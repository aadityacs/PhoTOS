{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import yaml\n",
    "import pickle\n",
    "from typing import Any, Union, List, Tuple, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import optax\n",
    "from functools import partial\n",
    "from jax.tree_util import tree_map\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import mesher\n",
    "import network\n",
    "import utils\n",
    "import plot_utils\n",
    "\n",
    "Pytree = Any\n",
    "_Ext = utils.Extent\n",
    "plt.rcParams.update(plot_utils.high_res_plot_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./settings.yaml\", \"r\") as file:\n",
    "  config = yaml.safe_load(file)\n",
    "\n",
    "stamp_mesh_cfg = config['STAMP_MESH']\n",
    "stamp_bbox_cfg = config['STAMP_BBOX']\n",
    "\n",
    "nn_cfg = config['IMPLICIT_NN']\n",
    "train_cfg = config['VAE_TRAIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define stamp mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp_bbox = mesher.BoundingBox(x=_Ext(stamp_bbox_cfg['x_min'],\n",
    "                                       stamp_bbox_cfg['x_max']),\n",
    "                                y=_Ext(stamp_bbox_cfg['y_min'],\n",
    "                                       stamp_bbox_cfg['y_max'])\n",
    "                                )\n",
    "stamp_mesh = mesher.Mesher(nelx=stamp_mesh_cfg['nelx'],\n",
    "                           nely=stamp_mesh_cfg['nely'],\n",
    "                           bounding_box=stamp_bbox\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp_sdfs = np.load('../data/train_sdf_images.npy')\n",
    "\n",
    "num_train_stamps = stamp_sdfs.shape[0]\n",
    "\n",
    "fig, ax = plt.subplots(num_train_stamps, 2,  figsize=(6, 3*num_train_stamps))\n",
    "for i in range(num_train_stamps):\n",
    "  ax[i,0].imshow(stamp_sdfs[i,:,:,0].T, cmap='coolwarm', origin='lower')\n",
    "  ax[i,1].imshow(stamp_sdfs[i,:,:,0].T < 0, cmap='coolwarm', origin='lower')\n",
    "\n",
    "  ax[i,0].set_axis_off(); ax[i,1].set_axis_off()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = nn_cfg['latent_dim']\n",
    "implicit_hidden_dim = nn_cfg['hidden_dim']\n",
    "implicit_num_layers = nn_cfg['num_layers']\n",
    "implicit_siren_freq = nn_cfg['siren_freq']\n",
    "\n",
    "np_rng = np.random.default_rng(0)\n",
    "rand_key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_net = network.ConvoImplicitAutoEncoder(latent_dim=latent_dim,\n",
    "                                           implicit_hidden_dim=implicit_hidden_dim,\n",
    "                                           implicit_num_layers=implicit_num_layers,\n",
    "                                           implicit_siren_freq=implicit_siren_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = train_cfg['num_epochs']\n",
    "lr = train_cfg['lr']\n",
    "kl_factor = train_cfg['kl_factor']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_grads(grads: Pytree, max_norm = 0.01) -> Pytree:\n",
    "  \"\"\"\n",
    "  Clips gradients to have a maximum norm of max_norm.\n",
    "  \n",
    "  Args:\n",
    "    grads: A pytree of gradients to be clipped.\n",
    "    max_norm: The maximum allowed norm for the gradients.\n",
    "      \n",
    "  Returns:\n",
    "    A pytree of gradients with norms clipped to max_norm.\n",
    "  \"\"\"\n",
    "  def clip(grad: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Clip a single gradient array to have a maximum norm of max_norm.\n",
    "    \n",
    "    Args:\n",
    "      grad: A gradient array.\n",
    "        \n",
    "    Returns:\n",
    "      A clipped gradient array.\n",
    "    \"\"\"\n",
    "    norm = jnp.linalg.norm(grad)\n",
    "    return jnp.where(norm > max_norm, grad * (max_norm / norm), grad)\n",
    "\n",
    "  return tree_map(clip, grads)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(train_imgs: jnp.ndarray,\n",
    "                      mesh: mesher.Mesher,\n",
    "                      sdf_net: network.ConvoImplicitAutoEncoder,\n",
    "                      num_epochs: int,\n",
    "                      kl_factor: float,\n",
    "                      lr: float,\n",
    "                      key: jax.Array,\n",
    "                      load_save:str=None,\n",
    "                      print_interval: int = 10):\n",
    "  \n",
    "\n",
    "  \"\"\"\n",
    "  Train a convolutional implicit autoencoder on a set of training images.\n",
    "\n",
    "  Args:\n",
    "    train_imgs: Array of training images.\n",
    "    mesh: Mesher object containing mesh information.\n",
    "    sdf_net: Convolutional implicit autoencoder network.\n",
    "    num_epochs: Number of training epochs.\n",
    "    kl_factor: Weight of the KL divergence term in the loss function.\n",
    "    lr: Learning rate for the optimizer.\n",
    "    key: Random key for initialization.\n",
    "    load_save: Path to a file to load saved parameters from (optional).\n",
    "    print_interval: Interval at which to print training progress.\n",
    "\n",
    "  Returns:\n",
    "    A tuple containing the trained network, the final parameters,\n",
    "    the convergence history, the predicted images, and the final random key.\n",
    "  \"\"\"\n",
    "\n",
    "  mesh_xy = mesh.elem_centers\n",
    "  solver = optax.adam(lr)\n",
    "  params = sdf_net.init(key, train_imgs,  mesh_xy, key)['params']\n",
    "\n",
    "  if load_save is not None:\n",
    "    with open(load_save, 'rb') as f:\n",
    "      params = pickle.load(f)\n",
    "\n",
    "  solver_state = solver.init(params)\n",
    "\n",
    "  def predict(params, key, is_training: bool):\n",
    "    return sdf_net.apply({'params': params}, train_imgs, mesh_xy, key, is_training)\n",
    "\n",
    "\n",
    "  @jax.jit\n",
    "  def loss_fn(params, key):\n",
    "\n",
    "    pred_sdf, enc_mu, enc_sigma, _ = predict(params, key, is_training=True)\n",
    "    pred_sdf = (pred_sdf.reshape(-1, mesh.nelx, mesh.nely, 1))\n",
    "\n",
    "    recons_loss = jnp.mean(((pred_sdf - train_imgs)/stamp_bbox.diag_length)**2)\n",
    "    kl_loss = (enc_sigma**2 + enc_mu**2 - jnp.log(enc_sigma) - 1./2.).sum()\n",
    "    net_loss = recons_loss +  kl_factor*kl_loss\n",
    "    \n",
    "    return net_loss, (recons_loss, kl_loss, pred_sdf)\n",
    "\n",
    "  @jax.jit\n",
    "  def train_step(params, solver_state, key):\n",
    "    subkey, key = jax.random.split(key)\n",
    "    (loss, aux), grad = jax.value_and_grad(loss_fn, has_aux=True)(params, subkey)\n",
    "\n",
    "    clipped_grads = clip_grads(grad)\n",
    "    updates, solver_state = solver.update(clipped_grads, solver_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, solver_state, loss, aux, key\n",
    "\n",
    "  convg_history = {'recons_loss':[], 'kl_loss':[], 'net_loss':[]}\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "    params, solver_state, train_loss, train_aux, key = train_step(params,\n",
    "                                                                  solver_state,\n",
    "                                                                  key)\n",
    "    \n",
    "    if epoch%print_interval == 0:\n",
    "      print(f'epoch {epoch:d}, recons_loss {train_aux[0]:.2E}, kl_loss {train_aux[1]:.2E} '\n",
    "            f' , net_loss {train_loss:.2E}')\n",
    "      \n",
    "      convg_history['recons_loss'].append(train_aux[0])\n",
    "      convg_history['kl_loss'].append(train_aux[1])\n",
    "      convg_history['net_loss'].append(train_loss)\n",
    "\n",
    "\n",
    "  (loss, train_aux), grad = jax.value_and_grad(loss_fn, has_aux=True)(params, key)\n",
    "  pred_imgs = train_aux[2]\n",
    "\n",
    "  return sdf_net, params, convg_history, pred_imgs, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_net, params, convg_history, pred_imgs, key = train_autoencoder(\n",
    "                                          train_imgs=stamp_sdfs,\n",
    "                                          mesh=stamp_mesh,\n",
    "                                          sdf_net=sdf_net,\n",
    "                                          num_epochs=num_epochs,\n",
    "                                          kl_factor=kl_factor,\n",
    "                                          lr=lr,\n",
    "                                          key=rand_key,\n",
    "                                          print_interval=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(file_name):\n",
    "  with open(file_name, 'wb') as f:\n",
    "    pickle.dump(params, f)\n",
    "save_weights('../data/sdf_vae_net_weights.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viz the training and latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sdf_vae_net_weights.pkl', 'rb') as f:\n",
    "  sdf_net_params_loaded = pickle.load(f)\n",
    "dec_stamp_sdf, _, _, _ = sdf_net.apply({'params': sdf_net_params_loaded},\n",
    "                              stamp_sdfs,\n",
    "                              stamp_mesh.elem_centers,\n",
    "                              False)\n",
    "dec_stamp_sdf = (dec_stamp_sdf.reshape(-1, stamp_mesh.nelx, stamp_mesh.nely, 1))\n",
    "print(dec_stamp_sdf.shape)\n",
    "for i in range(dec_stamp_sdf.shape[0]):\n",
    "\n",
    "  fig, ax = plt.subplots(1, 4)\n",
    "  img = ax[0].imshow(dec_stamp_sdf[i,:,:,0].T <0 , cmap='coolwarm',\n",
    "                     origin='lower')\n",
    "  \n",
    "  img = ax[1].imshow(stamp_sdfs[i,:,:,0].T <0 , cmap='coolwarm',\n",
    "                     origin='lower')\n",
    "  img = ax[2].imshow(dec_stamp_sdf[i,:,:,0].T , cmap='coolwarm',\n",
    "                     origin='lower')\n",
    "  img = ax[3].imshow(stamp_sdfs[i,:,:,0].T , cmap='coolwarm',\n",
    "                     origin='lower')\n",
    "  for j in range(4):\n",
    "    ax[j].set_axis_off()\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
